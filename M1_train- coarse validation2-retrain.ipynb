{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prerna Singh Cell-Detection Project\n",
    "# Tradional 3D CNN - Training using Clarity Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data as data\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pdb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pylab\n",
    "from numpy import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparamters\n",
    "num_epochs = 200\n",
    "batch_size = 5\n",
    "learning_rate = 1e-3\n",
    "momentum = 0.9\n",
    "dr = 0.3\n",
    "weight_decay = 1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Number of Cell Regions:  2028\n",
      "Number of Non-Cell Regions: 19682\n",
      "(19682, 12, 12, 12)\n",
      "(2028, 12, 12, 12)\n",
      "Total Number of Cell Regions:  607\n",
      "Number of Non-Cell Regions: 6070\n",
      "(6070, 12, 12, 12)\n",
      "(607, 12, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "# 0. Loading Data\n",
    "#\n",
    "# loading extracted cells and non cell Regions Of Interest\n",
    "\n",
    "ROI6L = np.load('ROI6L_bias_corrected.npy') \n",
    "ROI12R = np.load('ROI12R_bias_corrected.npy')\n",
    "ROI6R = np.load('ROI6L_bias_corrected.npy')\n",
    "ROI11R = np.load('ROI11R_bias_corrected.npy')\n",
    "ROI9R = np.load('ROI9R_bias_corrected.npy')\n",
    "FN2=np.load('FN2.npy')\n",
    "ROI_TRAIN = np.vstack((ROI6L,ROI12R,ROI6R,ROI11R,ROI9R,FN2))\n",
    "print(\"Total Number of Cell Regions: \", len(ROI_TRAIN))\n",
    "\n",
    "NCR6L = np.load('NCR6L_bias_corrected.npy') \n",
    "NCR12R = np.load('NCR12R_bias_corrected.npy')\n",
    "NCR6R = np.load('NCR6L_bias_corrected.npy')\n",
    "NCR11R = np.load('NCR11R_bias_corrected.npy')\n",
    "NCR9R = np.load('NCR9R_bias_corrected.npy')\n",
    "FP2=np.load('FP2.npy')\n",
    "NCR_TRAIN = np.vstack((NCR6L,NCR12R,NCR6R,NCR11R,NCR9R,FP2))\n",
    "print(\"Number of Non-Cell Regions:\",len(NCR_TRAIN))\n",
    "\n",
    "NCR_TRAIN = np.asarray(NCR_TRAIN)\n",
    "print(NCR_TRAIN.shape)\n",
    "\n",
    "ROI_TRAIN = np.asarray(ROI_TRAIN)\n",
    "print(ROI_TRAIN.shape)\n",
    "\n",
    "ROI12L = np.load('ROI12L_bias_corrected.npy') \n",
    "ROI9L = np.load('ROI9L_bias_corrected.npy') \n",
    "ROI10R = np.load('ROI10R_bias_corrected.npy')\n",
    "ROI_TEST = np.vstack((ROI12L,ROI9L,ROI10R))\n",
    "print(\"Total Number of Cell Regions: \", len(ROI_TEST))\n",
    "\n",
    "NCR12L = np.load('NCR12L_bias_corrected.npy') \n",
    "NCR9L = np.load('NCR9L_bias_corrected.npy') \n",
    "NCR10R = np.load('NCR10R_bias_corrected.npy')\n",
    "NCR_TEST = np.vstack((NCR12L,NCR9L,NCR10R))\n",
    "print(\"Number of Non-Cell Regions:\",len(NCR_TEST))\n",
    "\n",
    "NCR_TEST = np.asarray(NCR_TEST)\n",
    "print(NCR_TEST.shape)\n",
    "\n",
    "ROI_TEST = np.asarray(ROI_TEST)\n",
    "print(ROI_TEST.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Items in Train Data: 21710\n",
      "Shape of Train Data Vector: (21710, 1, 12, 12, 12)\n",
      "Number of Items in Test Data: 6677\n",
      "Shape of Test Data Vector: (6677, 1, 12, 12, 12)\n"
     ]
    }
   ],
   "source": [
    "#training and testing dataset\n",
    "\n",
    "train = np.vstack((ROI_TRAIN,NCR_TRAIN))\n",
    "#Train Data: 0-1545 = cell\n",
    "#Train Data: 1545-16995 = non cell region\n",
    "print('Number of Items in Train Data: %s' % len(train))\n",
    "train = np.expand_dims(train, axis=1)\n",
    "# expanded to fit network architecture of 1 channel. \n",
    "print('Shape of Train Data Vector:', train.shape)\n",
    "\n",
    "test = np.vstack((ROI_TEST, NCR_TEST))\n",
    "#Test Data: 0-956 = cell\n",
    "#Test Data: 956-10516 = non cell region\n",
    "print(\"Number of Items in Test Data: %s\" %len(test))\n",
    "test = np.expand_dims(test, axis=1)\n",
    "print('Shape of Test Data Vector:', test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating labels for training and testing dataset\n",
    "\n",
    "target_train = []\n",
    "target_test =[]\n",
    "\n",
    "for i in range(0,2028):\n",
    "    target_train.append(np.array([1]))\n",
    "# create 1085 labels for Yes Cell.\n",
    "\n",
    "for i in range(2028,21710):\n",
    "    target_train.append(np.array([0]))\n",
    "# create 1085 labels for No Cell.\n",
    "\n",
    "for i in range(0,607):\n",
    "    target_test.append(np.array([1]))\n",
    "# create 275 labels for Yes Cell.\n",
    "\n",
    "for i in range(0,6070):\n",
    "    target_test.append(np.array([0]))\n",
    "# create 275 labels for No Cell.\n",
    "\n",
    "target_train = np.array(target_train)\n",
    "target_test = np.array(target_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train dataset conversion: np array -> torch tensor -> torch dataset\n",
    "\n",
    "train_dataset = data.TensorDataset(torch.from_numpy(train), torch.from_numpy(target_train))\n",
    "# create a custom tensor train dataset from numpy array. \n",
    "#print(torch.from_numpy(target_train).size())\n",
    "train_loader = data.DataLoader(dataset = train_dataset, batch_size = batch_size, shuffle = True)\n",
    "# batch dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([6677, 1, 12, 12, 12])\n",
      "torch.Size([6677, 1])\n"
     ]
    }
   ],
   "source": [
    "#test dataset conversion: np array -> torch tensor -> torch dataset\n",
    "test_dataset = data.TensorDataset(torch.from_numpy(test), torch.from_numpy(target_test))\n",
    "print(torch.from_numpy(test).size())\n",
    "print(torch.from_numpy(target_test).size())\n",
    "# create a custom tensor test dataset from numpy array.\n",
    "\n",
    "test_loader = data.DataLoader(dataset = test_dataset, batch_size = 1, shuffle = False)\n",
    "# batch dataloader.\n",
    "# no shuffling for test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Model Architecture\n",
    "# INPUT: \n",
    "# - 1 x 12 x 12 x 12 image\n",
    "# CONV1: 3d CONV\n",
    "# MAXPOOL: 3d MP\n",
    "# CONV2: 3d CONV\n",
    "# CONV3: 3d CONV\n",
    "# FC1: Fully Connected Layer\n",
    "# FC2: Fully Connected Layer\n",
    "\n",
    "class M1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(M1, self).__init__()\n",
    "        self.conv1 = nn.Sequential(nn.Conv3d(1,64, (5,5,5),padding = 2),nn.Dropout(dr)) # in_channel, out_channel, kernel\n",
    "        self.pool = nn.MaxPool3d((2, 2, 2),2) # kernel, stride\n",
    "        self.conv2 = nn.Sequential(nn.Conv3d(64, 64, (3,3,3), padding = 1), nn.Dropout(dr)) # in_channel, out_channel, kernel\n",
    "        self.conv3 = nn.Sequential(nn.Conv3d(64, 64, (3,3,3), padding = 1), nn.Dropout(dr)) # in_channel, out_channel, kernel\n",
    "        self.fc1 = nn.Sequential(nn.Linear(6*6*6*64,150),nn.Dropout(dr))\n",
    "        self.fc2 = nn.Sequential(nn.Linear(150,1),nn.Dropout(dr))\n",
    "\n",
    "    def forward(self,x):\n",
    "#        print('Input Shape: ', x.shape)\n",
    "        x = F.relu(self.conv1(x))\n",
    "#        print('Shape after CONV1: ', x.shape)\n",
    "        # Conv1 Activation: ReLU\n",
    "        x = self.pool(x)\n",
    "#         print('Shape after Maxpool: ', x.shape)\n",
    "        # Followed by Maxpool\n",
    "     \n",
    "        x = F.relu(self.conv2(x))\n",
    "#         print('Shape after CONV2: ', x.shape)\n",
    "        # Conv2 Activation: ReLU\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "#         print('Shape after CONV3: ', x.shape)\n",
    "        # Conv3 Activation: ReLU\n",
    "        \n",
    "        x = x.reshape(x.size(0),-1)\n",
    "#         print('Shape after flatten: ', x.shape)\n",
    "        # flatten vector\n",
    "              \n",
    "        x = F.relu(self.fc1(x))\n",
    "        # FC1 Activation: ReLU\n",
    "#         print('Shape after FC1: ', x.shape)\n",
    "        x = self.fc2(x)\n",
    "        # FC2 Activation: None\n",
    "#         print('Shape after FC2: ', x.shape)\n",
    "        m = nn.Sigmoid()\n",
    "#         print('Shape after Sigmoid Output: ', x.shape)\n",
    "\n",
    "        x = m(x)\n",
    "        # Output Activation: Sigmoid\n",
    "        return x\n",
    "\n",
    "m1 = M1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Loss and Optimizer\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "# Binary Cross Entropy Loss\n",
    "\n",
    "optimizer = optim.SGD(m1.parameters(), lr = learning_rate, weight_decay = weight_decay)\n",
    "# SGD Optimizer\n",
    "# Regularization: Weight Decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for Validation Accuracy (to be used during training as well)\n",
    "\n",
    "def testAccuracy(test_loader, m1):\n",
    "    m1.eval()  # eval mode (batchnorm uses moving mean/variance instead of mini-batch mean/variance)\n",
    "    m1.to(device)\n",
    "    with torch.no_grad(): # don't compute grads because we're not backpropagating.\n",
    "        \n",
    "        correct = 0 # number of correctly guessed cases\n",
    "        valloss = 0 # validation loss\n",
    "        total = 0 # total number of cases\n",
    "        \n",
    "        # Use Test Dataset to Compute Validation Loss\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            images = images.float()\n",
    "            labels = labels.float()\n",
    "\n",
    "\n",
    "            outputs = m1(images)\n",
    "            predicted = (outputs>0.5).float()\n",
    "\n",
    "            \n",
    "            #print(\"target label: \",labels)\n",
    "            # What the target label is\n",
    "            \n",
    "            #print(\"predicted label: \",predicted)\n",
    "            # What the model predicts the label to be\n",
    "\n",
    "            # go through the vector of predicted labels\n",
    "            for i in range(len(predicted)):\n",
    "                if predicted[i] == labels[i]:\n",
    "                    correct += 1\n",
    "                    \n",
    "            #print('number of correct matches: ', correct)\n",
    "            # number of correct label matches\n",
    "            total += len(labels)\n",
    "            \n",
    "            loss = criterion(outputs, labels)\n",
    "            # compute loss between target label and predicted output label (unrounded this time)\n",
    "            \n",
    "            valloss += loss.item()\n",
    "            # should this be +=?\n",
    "\n",
    "        \n",
    "    \n",
    "    accruacy = correct/total * 100\n",
    "    return valloss, accruacy\n",
    "    #print('Test Accuracy of the model on the test images: {} %'.format(100 * correct / 38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Training Loop\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "m1.to(device)\n",
    "\n",
    "total_loss = []\n",
    "total_accuracy = []\n",
    "valloss =[]\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    steploss = 0\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        #print(\"image\",images.shape)\n",
    "        labels = labels.to(device)\n",
    "        #print(labels.shape)\n",
    "        images = images.float()\n",
    "        labels = labels.float()\n",
    "        \n",
    "        outputs = m1(images)\n",
    "        #print(\"ouput shape: \",outputs.shape)\n",
    "        #print(\"outputs: \", outputs)\n",
    "        #pdb.set_trace()\n",
    "        #print('target label:',labels)\n",
    "        #loss = criterion(outputs, torch.max(labels, 1)[1])\n",
    "        loss = criterion(outputs, labels)\n",
    "        steploss += loss.item()\n",
    "       \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n",
    "        \n",
    "    total_loss.append(steploss)\n",
    "    total_accuracy.append(testAccuracy(test_loader, m1)[1])\n",
    "    \n",
    "    valloss.append(testAccuracy(test_loader,m1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[98.18780889621087,\n",
       " 98.38250711397333,\n",
       " 98.75692676351655,\n",
       " 99.19125355698667,\n",
       " 99.14632319904149,\n",
       " 99.20623034296841,\n",
       " 99.23618391493186,\n",
       " 98.98157855324247,\n",
       " 99.25116070091359,\n",
       " 98.87674105137037,\n",
       " 99.25116070091359,\n",
       " 99.19125355698667,\n",
       " 99.07143926913284,\n",
       " 99.1612999850232,\n",
       " 97.8882731765763,\n",
       " 99.17627677100495,\n",
       " 99.1612999850232,\n",
       " 99.20623034296841,\n",
       " 99.3110678448405,\n",
       " 99.34102141680395,\n",
       " 99.41590534671259,\n",
       " 99.40092856073088,\n",
       " 99.20623034296841,\n",
       " 97.78343567470421,\n",
       " 98.87674105137037,\n",
       " 99.46083570465778,\n",
       " 99.35599820278568,\n",
       " 99.3110678448405,\n",
       " 99.28111427287703,\n",
       " 99.22120712895013,\n",
       " 99.41590534671259,\n",
       " 99.49078927662124,\n",
       " 99.29609105885876,\n",
       " 99.44585891867605,\n",
       " 98.92167140931556,\n",
       " 99.14632319904149,\n",
       " 99.46083570465778,\n",
       " 99.43088213269432,\n",
       " 99.3110678448405,\n",
       " 99.41590534671259,\n",
       " 99.38595177474913,\n",
       " 99.46083570465778,\n",
       " 99.4758124906395,\n",
       " 99.50576606260296,\n",
       " 99.5207428485847,\n",
       " 99.3110678448405,\n",
       " 99.29609105885876,\n",
       " 99.46083570465778,\n",
       " 99.38595177474913,\n",
       " 99.37097498876741,\n",
       " 99.38595177474913,\n",
       " 99.50576606260296,\n",
       " 99.20623034296841,\n",
       " 99.43088213269432,\n",
       " 99.38595177474913,\n",
       " 99.3110678448405,\n",
       " 99.44585891867605,\n",
       " 99.38595177474913,\n",
       " 99.32604463082222,\n",
       " 99.43088213269432,\n",
       " 99.62558035045679,\n",
       " 99.61060356447507,\n",
       " 99.62558035045679,\n",
       " 99.38595177474913,\n",
       " 99.44585891867605,\n",
       " 99.61060356447507,\n",
       " 99.55069642054815,\n",
       " 99.58064999251161,\n",
       " 99.40092856073088,\n",
       " 99.37097498876741,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.62558035045679,\n",
       " 99.58064999251161,\n",
       " 99.5207428485847,\n",
       " 99.55069642054815,\n",
       " 99.49078927662124,\n",
       " 99.56567320652988,\n",
       " 98.75692676351655,\n",
       " 99.58064999251161,\n",
       " 99.59562677849334,\n",
       " 99.55069642054815,\n",
       " 99.50576606260296,\n",
       " 99.55069642054815,\n",
       " 99.5207428485847,\n",
       " 98.27766961210125,\n",
       " 99.50576606260296,\n",
       " 99.56567320652988,\n",
       " 99.55069642054815,\n",
       " 99.37097498876741,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.55069642054815,\n",
       " 99.59562677849334,\n",
       " 99.61060356447507,\n",
       " 99.55069642054815,\n",
       " 99.61060356447507,\n",
       " 99.61060356447507,\n",
       " 99.61060356447507,\n",
       " 99.61060356447507,\n",
       " 99.61060356447507,\n",
       " 99.61060356447507,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.59562677849334,\n",
       " 99.59562677849334,\n",
       " 99.61060356447507,\n",
       " 99.59562677849334,\n",
       " 99.59562677849334,\n",
       " 99.58064999251161,\n",
       " 99.59562677849334,\n",
       " 99.58064999251161,\n",
       " 99.59562677849334,\n",
       " 99.56567320652988,\n",
       " 99.61060356447507,\n",
       " 99.59562677849334,\n",
       " 99.59562677849334,\n",
       " 99.59562677849334,\n",
       " 99.55069642054815,\n",
       " 99.62558035045679,\n",
       " 99.59562677849334,\n",
       " 99.59562677849334,\n",
       " 99.59562677849334,\n",
       " 99.56567320652988,\n",
       " 99.61060356447507,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.59562677849334,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.59562677849334,\n",
       " 99.58064999251161,\n",
       " 99.59562677849334,\n",
       " 99.59562677849334,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.55069642054815,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.59562677849334,\n",
       " 99.59562677849334,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.55069642054815,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.55069642054815,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.55069642054815,\n",
       " 99.58064999251161,\n",
       " 99.59562677849334,\n",
       " 99.58064999251161,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161,\n",
       " 99.59562677849334,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.56567320652988,\n",
       " 99.58064999251161]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(m1.state_dict(), 'coarsevalidation2retrain.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#how to load model\n",
    "#m1 = M1()\n",
    "#m1.load_state_dict(torch.load('model_trained_on6L6R9L.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
